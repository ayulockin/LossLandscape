{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmallCNN_Cifar10",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMt6i2VuCWvQNAoJBy/7e0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/LossLandscape/blob/master/SmallCNN_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKzu9hbgqw2x",
        "colab_type": "text"
      },
      "source": [
        "# Setups, Installations and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT_P8aSjO-ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "2607385e-0697-4750-d4e5-cd801fc3e2fc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 14 13:53:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQAggd-btWJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "43a559fd-e051-4425-e76a-29a15f753ab2"
      },
      "source": [
        "## This is so that I can save my models.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAZBTFNQq0ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-APP7-6C5uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SEED = 666\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.random.set_seed(SEED)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import resnet50\n",
        "\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pr3HrMxq8SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "import numpy as np\n",
        "# np.random.seed(SEED)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from PIL import Image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVkQbw_q_07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "6f7e03e5-b19b-4311-90c1-1b30ce903600"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Ln8W0Aru8X",
        "colab_type": "text"
      },
      "source": [
        "# Download and Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMFYLweasySz",
        "colab_type": "text"
      },
      "source": [
        "#### CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Posjlu7lDJBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "69c3eb13-e9cb-4144-c604-3a038c10f172"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcM1SXdiGVf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASS_NAMES = (\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDLO83axDOzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7d06ce4-5897-421d-a5e9-bc54673a5887"
      },
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzY01xwxS-f",
        "colab_type": "text"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TqcgM67xxDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "IMG_SHAPE = 32\n",
        "\n",
        "trainloader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "testloader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "  img = tf.cast(image, tf.float32)\n",
        "  img = img/255.\n",
        "\n",
        "  return img, label\n",
        "\n",
        "trainloader = (\n",
        "    trainloader\n",
        "    .shuffle(1024)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "testloader = (\n",
        "    testloader\n",
        "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2xrs00QuVG3",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pv7-2VNsb5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Model():\n",
        "  inputs = keras.layers.Input(shape=(IMG_SHAPE, IMG_SHAPE, 3))\n",
        "\n",
        "  x = keras.layers.Conv2D(16, (3,3), padding='same')(inputs)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = keras.layers.MaxPooling2D(2, strides=2)(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(32,(3,3), padding='same')(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = keras.layers.MaxPooling2D(2, strides=2)(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(32,(3,3), padding='same')(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = keras.layers.MaxPooling2D(2, strides=2)(x)\n",
        "\n",
        "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "  x = keras.layers.Dense(32, activation='relu')(x)\n",
        "  x = keras.layers.Dropout(0.1)(x)\n",
        "  \n",
        "  outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "  return keras.models.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkxDAl8pv5pJ",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4WY47Kxv8uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Custom LR schedule as mentioned in the LossLandscape paper\n",
        "LR_SCHEDULE = [\n",
        "    # (epoch to start, learning rate) tuples\n",
        "    (0, 1.6*1e-3),\n",
        "    (9, (1.6*1e-3)/2),\n",
        "    (19, (1.6*1e-3)/4),\n",
        "    (29, (1.6*1e-3)/8),\n",
        "]\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    if (epoch >= 0) & (epoch < 9):\n",
        "        return LR_SCHEDULE[0][1]\n",
        "    elif (epoch >= 9) & (epoch < 19):\n",
        "        return LR_SCHEDULE[1][1]\n",
        "    elif (epoch >= 19) & (epoch < 29):\n",
        "        return LR_SCHEDULE[2][1]\n",
        "    else:\n",
        "        return LR_SCHEDULE[3][1]\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lr_schedule(epoch), verbose=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q02l2PnW4YMh",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7NGdxodMYP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "b2e4c5b7-7695-4d0d-cad6-8e43659d4d13"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model = Model()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Relu (TensorFlow [(None, 32, 32, 16)]      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Relu_1 (TensorFl [(None, 16, 16, 32)]      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Relu_2 (TensorFl [(None, 8, 8, 32)]        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 15,722\n",
            "Trainable params: 15,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqiY2v174cCw",
        "colab_type": "text"
      },
      "source": [
        "# Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Vk7qmEMgeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP5elumu4eJG",
        "colab_type": "text"
      },
      "source": [
        "# Wandb Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svw-ocG_yeGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5facabff-d23a-4b01-df96-4fff63721ff0"
      },
      "source": [
        "wandb.init(entity='ayush-thakur', project='loss-landscape')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/loss-landscape\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/loss-landscape</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/loss-landscape/runs/113w8hol\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/loss-landscape/runs/113w8hol</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "W&B Run: https://app.wandb.ai/ayush-thakur/loss-landscape/runs/113w8hol"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co0IcwRl4goi",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mqy_ZBNM8UA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "319b01d1-1c9a-4940-ffb2-92fba0702329"
      },
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "_ = model.fit(trainloader,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=testloader,\n",
        "          callbacks=[WandbCallback(),\n",
        "                     lr_callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 1/40\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.9124 - acc: 0.2755 - val_loss: 1.6872 - val_acc: 0.3756 - lr: 0.0016\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 2/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.6516 - acc: 0.3821 - val_loss: 1.4989 - val_acc: 0.4459 - lr: 0.0016\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 3/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.5316 - acc: 0.4298 - val_loss: 1.4783 - val_acc: 0.4502 - lr: 0.0016\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 4/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.4538 - acc: 0.4589 - val_loss: 1.3666 - val_acc: 0.4890 - lr: 0.0016\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 5/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.3951 - acc: 0.4851 - val_loss: 1.2946 - val_acc: 0.5246 - lr: 0.0016\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 6/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.3436 - acc: 0.5036 - val_loss: 1.2744 - val_acc: 0.5282 - lr: 0.0016\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 7/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.3062 - acc: 0.5217 - val_loss: 1.2853 - val_acc: 0.5385 - lr: 0.0016\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 8/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.2669 - acc: 0.5371 - val_loss: 1.2026 - val_acc: 0.5615 - lr: 0.0016\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0016.\n",
            "Epoch 9/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.2404 - acc: 0.5471 - val_loss: 1.2244 - val_acc: 0.5553 - lr: 0.0016\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 10/40\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.1914 - acc: 0.5668 - val_loss: 1.1768 - val_acc: 0.5738 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 11/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1813 - acc: 0.5708 - val_loss: 1.1639 - val_acc: 0.5754 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 12/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1661 - acc: 0.5787 - val_loss: 1.1475 - val_acc: 0.5831 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 13/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.1514 - acc: 0.5823 - val_loss: 1.1213 - val_acc: 0.5985 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 14/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.1380 - acc: 0.5878 - val_loss: 1.1068 - val_acc: 0.6042 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 15/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1260 - acc: 0.5924 - val_loss: 1.0931 - val_acc: 0.6055 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 16/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1176 - acc: 0.5966 - val_loss: 1.0935 - val_acc: 0.6098 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 17/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1033 - acc: 0.6037 - val_loss: 1.0867 - val_acc: 0.6081 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 18/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1015 - acc: 0.6007 - val_loss: 1.0705 - val_acc: 0.6178 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0008.\n",
            "Epoch 19/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0870 - acc: 0.6096 - val_loss: 1.1216 - val_acc: 0.5975 - lr: 8.0000e-04\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 20/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0603 - acc: 0.6167 - val_loss: 1.0420 - val_acc: 0.6256 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 21/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0519 - acc: 0.6211 - val_loss: 1.0508 - val_acc: 0.6243 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 22/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0516 - acc: 0.6216 - val_loss: 1.0396 - val_acc: 0.6280 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 23/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0413 - acc: 0.6252 - val_loss: 1.0337 - val_acc: 0.6313 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 24/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0370 - acc: 0.6283 - val_loss: 1.0297 - val_acc: 0.6337 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 25/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0303 - acc: 0.6297 - val_loss: 1.0177 - val_acc: 0.6368 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 26/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0269 - acc: 0.6310 - val_loss: 1.0442 - val_acc: 0.6269 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 27/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0227 - acc: 0.6342 - val_loss: 1.0169 - val_acc: 0.6373 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 28/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0172 - acc: 0.6356 - val_loss: 1.0203 - val_acc: 0.6382 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 29/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0100 - acc: 0.6386 - val_loss: 1.0275 - val_acc: 0.6341 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 30/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9982 - acc: 0.6441 - val_loss: 1.0015 - val_acc: 0.6432 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 31/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9962 - acc: 0.6432 - val_loss: 0.9989 - val_acc: 0.6460 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 32/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9926 - acc: 0.6446 - val_loss: 0.9965 - val_acc: 0.6448 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 33/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9915 - acc: 0.6476 - val_loss: 1.0004 - val_acc: 0.6451 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 34/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9880 - acc: 0.6463 - val_loss: 1.0001 - val_acc: 0.6440 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 35/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9870 - acc: 0.6467 - val_loss: 1.0072 - val_acc: 0.6441 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 36/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9824 - acc: 0.6472 - val_loss: 1.0014 - val_acc: 0.6419 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 37/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9824 - acc: 0.6482 - val_loss: 0.9891 - val_acc: 0.6490 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 38/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9796 - acc: 0.6505 - val_loss: 0.9870 - val_acc: 0.6491 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 39/40\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.9761 - acc: 0.6507 - val_loss: 0.9982 - val_acc: 0.6464 - lr: 2.0000e-04\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0002.\n",
            "Epoch 40/40\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9755 - acc: 0.6523 - val_loss: 0.9870 - val_acc: 0.6503 - lr: 2.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKv6UHqM1I3Q",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO_E5WFAclHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a72d11aa-21d0-4c90-b5bc-5682884a4750"
      },
      "source": [
        "loss, accuracy = model.evaluate(testloader, callbacks=[WandbCallback()])\n",
        "print(\"Test Error Rate: \", round((1-accuracy)*100, 2), '%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 7ms/step - loss: 0.9870 - acc: 0.6503\n",
            "Test Error Rate:  34.97 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}